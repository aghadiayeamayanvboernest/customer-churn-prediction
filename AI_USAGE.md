# AI Usage in the Customer Churn Prediction Project

This document outlines how AI assistance, specifically large language models, was used to enhance the development of this project. While the core logic and architecture were designed and implemented by Aghadiaye Ernest the primary developer, AI was leveraged for specific tasks to improve code quality, generate documentation, and accelerate development.

## What AI Helped With

AI assistance was primarily used for the following purposes:

1.  **Code Refactoring and Enhancement:**
    *   **Function Optimization:** AI was prompted to refactor complex functions for better readability and performance. For example, the `train_and_evaluate_models` function in `src/train_models.py` was refactored to be more modular and easier to understand.
    *   **Improving Visualizations:** AI helped in generating the code for more appealing and informative visualizations, such as the styled metric cards in the Streamlit sidebar (`src/sidebar.py`) and the detailed SHAP summary plots in `src/interpretability.py`.
    *   **Error Handling:** AI was used to suggest and implement more robust error handling, for instance, in the data loading functions in `src/clv_analysis.py`.

2.  **Documentation and Comments:**
    *   **Docstring Generation:** AI was used to generate detailed docstrings for functions across the project, ensuring that the purpose, arguments, and return values of each function were clearly documented.
    *   **README and Markdown Content:** AI helped in structuring and writing sections of the `README.md` file and this `AI_USAGE.md` file.

3.  **Generating Plotting Code:**
    *   AI was used to generate boilerplate code for `matplotlib` and `seaborn` plots, which was then customized. For example, the initial code for the confusion matrix and ROC curve plots in `src/tabs/model_performance_tab.py` was generated by AI.

## The Prompts That Mattered

Here are some examples of prompts that led to significant improvements in the codebase:

*   **For Refactoring `train_and_evaluate_models`:**
    > "Refactor this Python function to improve its structure. Separate the data scaling, model definition, and evaluation loop into distinct parts. Also, suggest a better way to store and display the results."

*   **For Enhancing the Streamlit UI:**
    > "I'm using Streamlit. I want to display key metrics in the sidebar. Can you provide the Python code to create visually appealing 'cards' for each metric, using custom HTML and CSS for styling? The metrics are Total Customers, Overall Churn Rate, and Average CLV."

*   **For Generating SHAP Plot Code:**
    > "Using the `shap` library in Python, generate the code to create and save a SHAP summary plot and a bar plot for a trained XGBoost model. The plots should be saved to a file."

*   **For Generating Docstrings:**
    > "Generate a comprehensive docstring for the following Python function. The docstring should follow the Google Python Style Guide and include descriptions for all arguments and the return value."
    >
    > ```python
    > def explain_logistic_regression(model, X):
    >     # ... function code ...
    > ```

## What I Fixed/Verified

The code and text generated by the AI were not used blindly. Every suggestion and piece of generated code was subject to a thorough review and verification process:

1.  **Code Correctness and Logic:** All AI-generated code was carefully inspected to ensure it was logically correct and free of bugs. For example, in the refactored `train_and_evaluate_models` function, the order of operations (scaling, training, prediction) was manually verified.

2.  **Adherence to Project Conventions:** The generated code was modified to fit the existing coding style, naming conventions, and architectural patterns of the project.

3.  **Testing:** The changes were tested to ensure they didn't introduce any regressions. For instance, after refactoring the model training script, the performance metrics were compared to the pre-refactoring results to ensure they remained consistent.

4.  **Factual Accuracy of Documentation:** All generated documentation was reviewed for technical accuracy and clarity. Any inaccuracies or ambiguities were corrected.

In summary, AI was used as a powerful assistant to augment the development process, not to replace the developer's critical thinking and oversight.

## AI Tools Used

The following AI tools were used in this project:

*   **ChatGPT:** Used for initial brainstorming and generating boilerplate code.
*   **Chat-based Gemini:** Used for interactive code generation, refactoring, and documentation assistance.
